参考资料具体来源见下方（排名不分先后）：

<https://github.com/the-web3/chaineye-blockchain-interview>

<https://github.com/xwal/Web3-Interview-Questions/tree/main/WTF-Solidity-Quiz>

<https://github.com/AmazingAng/WTF-Solidity>

<https://github.com/Metana-Inc/web3-interview-questions>

<https://github.com/rohitscript/Blockchain-Interview-Questions>

<https://gist.github.com/19sajib/d6a6b766bfdb5a4b0f670583f4917bca>

<https://github.com/sharpWit/Web3FrontEndInterview/>

<https://hackmd.io/@amintalebi/Bk1Zi0hm3>  

<https://blog.ibuidl.org/%E7%A4%BE%E5%8C%BA%E6%B4%BB%E5%8A%A8/ce4c1ebc-446c-49f7-b96a-61c4dd2937fc>

<https://www.tealhq.com/interview-questions/web3-developer>

<https://github.com/frankiefab100/Web3.0-Roadmap>

 <https://xiaolincoding.com/>

 <https://interviewguide.cn/notes/10-interview/0-guide.html>

<https://www.rareskills.io/post/solidity-interview-questions>

<https://github.com/the-web3/chaineye-blockchain-interview>

<https://learnblockchain.cn/article/7257>

<https://learnblockchain.cn/article/7260>

<https://learnblockchain.cn/article/7264>

<https://learnblockchain.cn/article/7268>

<https://learnblockchain.cn/article/7275>

<https://juejin.cn/post/7293392480452132874>

<https://binschool.org/solidity-test/solidity-test-basic.html>

<https://github.com/lengyue1024/BAT_interviews>

<https://binschool.org/solidity-test/solidity-test-intermediate.html>

<https://binschool.org/solidity-test/solidity-test-advanced.html>

<https://juejin.cn/post/7253466047890554939>

<https://www.analyticsvidhya.com/blog/2016/12/45-questions-to-test-a-data-scientist-on-regression-skill-test-regression-solution/>

<https://www.analyticsvidhya.com/blog/2016/11/solution-for-skilltest-machine-learning-revealed/>

<https://www.analyticsvidhya.com/blog/2017/04/40-questions-test-data-scientist-machine-learning-solution-skillpower-machine-learning-datafest-2017/>

<http://www.toptal.com/android/interview-questions>

<https://www.interviewbit.com/android-interview-questions/>

<https://adevait.com/android/interview-questions>

<https://github.com/mindash/android-structured-interview>

<https://github.com/sudheerj/reactjs-interview-questions>

<http://www.toptal.com/ios/interview-questions>

<http://www.toptal.com/swift/interview-questions>

<https://www.raywenderlich.com/762435-swift-interview-questions-and-answers>

<https://github.com/CameronBanga/iOS-Developer-and-Designer-Interview-Questions>

<https://mindmajix.com/docker-interview-questions>

<https://www.edureka.co/blog/interview-questions/docker-interview-questions/>

<https://www.fullstack.cafe/blog/docker-interview-questions-and-answers>

<https://www.techgeekbuzz.com/top-docker-interview-questions/>

<https://arc.dev/talent-blog/reactjs-interview-questions/>

<https://ui.dev/react-interview-questions>

<https://www.toptal.com/react/interview-questions>

<https://www.onlineinterviewquestions.com/typescript-interview-questions>

<https://github.com/sudheerj/reactjs-interview-questions>

<https://github.com/sudheerj/vuejs-interview-questions>

<https://www.simplilearn.com/vue-js-interview-questions-article>

<https://arc.dev/talent-blog/vue-interview-questions/>

<https://arc.dev/talent-blog/java-interview-questions/>

<https://www.toptal.com/java/interview-questions>

<https://www.janbasktraining.com/interview-questions/core-java-questions-answers/>

<https://blog.udemy.com/java-interview-questions/>

<https://www.bestinterviewquestion.com/rust-programming-language-interview-questions>

<https://www.turing.com/interview-questions/rust>

<https://www.code-sample.com/2018/02/rust-programming-interview-questions.html#main>

<http://www.toptal.com/python/interview-questions>

<https://www.interviewbit.com/python-interview-questions/>

<https://www.geeksforgeeks.org/python-interview-questions/>

<https://www.datacamp.com/blog/top-python-interview-questions-and-answers>

<https://juejin.cn/post/7200377381613666341?searchId=20250513222705F9FA492A8DDDCA68A2AA>

<https://juejin.cn/post/6988016003162570782>

<https://www.nowcoder.com/interview/center?entranceType=%E5%AF%BC%E8%88%AA%E6%A0%8F>

<https://juejin.cn/post/7242127432203665468>

<http://www.careerride.com/android-interview-questions.aspx>

<https://github.com/derekargueta/Android-Interview-Questions>

<https://medium.com/@neteinstein/not-another-android-interviews-article-the-questions-3dedafa30bec>

<https://juejin.cn/post/6844903901557161992>

[https://developer.nvidia.com/blog/mastering-llm-techniques-data-preprocessing/](https://developer.nvidia.com/blog/mastering-llm-techniques-data-preprocessing/)

[https://cn.blockchain.news/news/optimizing-llms-enhancing-data-preprocessing-techniques](https://cn.blockchain.news/news/optimizing-llms-enhancing-data-preprocessing-techniques)

[https://www.datacamp.com/blog/llm-interview-questions](https://www.datacamp.com/blog/llm-interview-questions)

[https://huggingface.co/course/chapter9/3?fw=pt](https://huggingface.co/course/chapter9/3?fw=pt)

[https://en.wikipedia.org/wiki/Transformer\_(deep\_learning\_architecture)](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture))

[https://machinelearningmastery.com/what-are-transformers/](https://machinelearningmastery.com/what-are-transformers/)

[https://www.ibm.com/think/topics/instruction-tuning](https://www.ibm.com/think/topics/instruction-tuning)

[https://arxiv.org/abs/2307.03185](https://arxiv.org/abs/2307.03185)

[https://developer.ibm.com/technologies/ai/articles/what-is-instruction-tuning/](https://developer.ibm.com/technologies/ai/articles/what-is-instruction-tuning/)

[https://community.juniper.net/blogs/sharada-yeluri/2023/10/03/large-language-models-the-hardware-connection](https://community.juniper.net/blogs/sharada-yeluri/2023/10/03/large-language-models-the-hardware-connection)

[https://www.deepspeed.ai/tutorials/large-models-w-deepspeed/](https://www.deepspeed.ai/tutorials/large-models-w-deepspeed/)

[https://aman.ai/primers/ai/grad-accum-checkpoint/](https://aman.ai/primers/ai/grad-accum-checkpoint/)

[https://pytorch.org/blog/what-every-user-should-know-about-mixed-precision-training-in-pytorch/](https://pytorch.org/blog/what-every-user-should-know-about-mixed-precision-training-in-pytorch/)

[https://huggingface.co/docs/autotrain/en/llm\_finetuning\_params](https://huggingface.co/docs/autotrain/en/llm_finetuning_params)

[https://www.nccgroup.com/us/research-blog/exploring-overfitting-risks-in-large-language-models/](https://www.nccgroup.com/us/research-blog/exploring-overfitting-risks-in-large-language-models/)

[https://arxiv.org/abs/2001.08361](https://arxiv.org/abs/2001.08361)

[https://arxiv.org/abs/2106.09685](https://arxiv.org/abs/2106.09685)

[https://developer.nvidia.com/blog/large-language-models-hardware](https://developer.nvidia.com/blog/large-language-models-hardware)

[https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/](https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/)

[https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/](https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/)

[https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/](https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/)

[https://skphd.medium.com/large-language-model-llm-interview-questions-ded6264547f1](https://skphd.medium.com/large-language-model-llm-interview-questions-ded6264547f1)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/](https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/)

[https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/](https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/)

[https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/](https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/)

[https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/](https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/)

[https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/](https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/)

[https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/](https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/)

[https://skphd.medium.com/large-language-model-llm-interview-questions-ded6264547f1](https://skphd.medium.com/large-language-model-llm-interview-questions-ded6264547f1)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/](https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://incubity.ambilio.com/top-20-llm-interview-questions/](https://incubity.ambilio.com/top-20-llm-interview-questions/)

[https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/](https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/](https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/)

[https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/](https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://huggingface.co/docs/transformers/en/training](https://huggingface.co/docs/transformers/en/training)

[https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/](https://www.geeksforgeeks.org/fine-tuning-large-language-model-llm/)

[https://huggingface.co/docs/autotrain/en/llm_finetuning_params](https://huggingface.co/docs/autotrain/en/llm_finetuning_params)

[https://huggingface.co/docs/autotrain/en/llm_finetuning_params](https://huggingface.co/docs/autotrain/en/llm_finetuning_params)

[https://skphd.medium.com/large-language-model-llm-interview-questions-ded6264547f1](https://skphd.medium.com/large-language-model-llm-interview-questions-ded6264547f1)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://huggingface.co/docs/autotrain/en/llm_finetuning_params](https://huggingface.co/docs/autotrain/en/llm_finetuning_params)

[https://huggingface.co/docs/autotrain/en/llm_finetuning_params](https://huggingface.co/docs/autotrain/en/llm_finetuning_params)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://huggingface.co/docs/autotrain/en/llm_finetuning_params](https://huggingface.co/docs/autotrain/en/llm_finetuning_params)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://skphd.medium.com/large-language-model-llm-interview-questions-ded6264547f1](https://skphd.medium.com/large-language-model-llm-interview-questions-ded6264547f1)

[https://huggingface.co/docs/transformers/en/hyperparameter_search](https://huggingface.co/docs/transformers/en/hyperparameter_search)

[https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/](https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-interview-questions-and-answers/)

[https://skphd.medium.com/large-language-model-llm-interview-questions-ded6264547f1](https://skphd.medium.com/large-language-model-llm-interview-questions-ded6264547f1)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://huggingface.co/docs/transformers/en/training](https://huggingface.co/docs/transformers/en/training)

[https://huggingface.co/docs/transformers/en/training](https://huggingface.co/docs/transformers/en/training)

[https://huggingface.co/docs/transformers/en/training](https://huggingface.co/docs/transformers/en/training)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://huggingface.co/docs/transformers/en/transformers_callbacks](https://huggingface.co/docs/transformers/en/transformers_callbacks)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://huggingface.co/docs/peft/main](https://huggingface.co/docs/peft/main)

[https://huggingface.co/docs/transformers/en/peft](https://huggingface.co/docs/transformers/en/peft)

[https://huggingface.co/docs/transformers/en/training](https://huggingface.co/docs/transformers/en/training)

<https://www.nowcoder.com/interview/center?entranceType=%E5%AF%BC%E8%88%AA%E6%A0%8F>

> 忽然发现牛客自动粘贴的来源链接都是一样的，前面没注意到......

<https://blog.csdn.net/qq_45659769/article/details/119515064>

<https://www.cnblogs.com/fairya/p/17323895.html>

<https://blog.csdn.net/qq_40522090/article/details/139922669>

<https://www.iamshuaidi.com/30237.html>
